{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ba07ed8f-4e03-419c-8c78-c5f409e08ac3",
   "metadata": {},
   "source": [
    "## Understanding the math underhood "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7fbd573-cecd-4c56-8b2b-641fe202a29b",
   "metadata": {},
   "source": [
    "1. logit = z $$z=wx+b$$\n",
    "2. likelihood function: $$\\sigma^y(z)[1-\\sigma(z)]^{1-y}$$ where $$\\sigma = \\frac{1}{1+e^{-z}}$$\n",
    "3. log-likelihood function: $$ln(\\sigma^y(z)[1-\\sigma(z)]^{1-y})$$ to make math easier\n",
    "4. Loss function for Logistic regression: $$-ln(\\sigma^y(z)[1-\\sigma(z)]^{1-y})$$\n",
    "$$or$$\n",
    "$$\\frac{1\\sum_{i=1}^m }{m}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1793ef76-f4c3-4876-946d-4c3780ecbfe1",
   "metadata": {},
   "source": [
    "## Manual practice\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "54645aac-00ae-403f-871e-ac37945a11d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the loss: 0.37110066594777763\n"
     ]
    }
   ],
   "source": [
    "# example 1\n",
    "y = 1\n",
    "w = 2.0\n",
    "x = 0.5\n",
    "b = -0.2\n",
    "\n",
    "# step 1: compute z \n",
    "z = w*x + b\n",
    "\n",
    "# step 2: estimate sigmoid(z)\n",
    "import math\n",
    "e = math.e\n",
    "sigmoid = 1/(1+e**(-z))\n",
    "\n",
    "# step 3: compute the likelihood\n",
    "likelihood = sigmoid**y *(1-sigmoid)**(1-y)\n",
    "\n",
    "# step 4: compute the log-likelihood\n",
    "import numpy as np\n",
    "def ln(x):\n",
    "    return np.log(x)\n",
    "log_lh = ln(likelihood)\n",
    "#print(log_lh)\n",
    "\n",
    "# step 5: compute\n",
    "loss = -log_lh\n",
    "print(f\"the loss: {loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "af86ab13-d1b7-40a7-a543-6526192e60f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logit: -1.4999999999999998\n",
      "sigmoid: 0.18242552380635638\n",
      "likelihood: 0.8175744761936437\n",
      "the log-likelihood: -0.2014132779827524\n",
      "the loss: 0.2014132779827524\n"
     ]
    }
   ],
   "source": [
    "# example 2:\n",
    "y = 0 \n",
    "w = -1.5\n",
    "x = 1.2\n",
    "b = 0.3\n",
    "\n",
    "# step 1: compute z\n",
    "z = w*x+b\n",
    "print(f\"logit: {z}\")\n",
    "\n",
    "# step 2 compute sigmoid\n",
    "sigmoid = 1/(1+e**(-z))\n",
    "print(f\"sigmoid: {sigmoid}\")\n",
    "\n",
    "# step 3 compute the likelihood\n",
    "lh = sigmoid**y * (1-sigmoid)**(1-y)\n",
    "print(f\"likelihood: {lh}\")\n",
    "\n",
    "# step 4 compute the log-likelihood\n",
    "log_lh = ln(lh)\n",
    "print(f\"the log-likelihood: {log_lh}\")\n",
    "\n",
    "# step 5 compute the loss\n",
    "loss = -log_lh\n",
    "print(f\"the loss: {loss}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31a5d606-d299-4d57-a2c4-bfc7f9d8b8c8",
   "metadata": {},
   "source": [
    "### negative ln-likelihood = cost function for logistic regression = binary cross-entropy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4e321de8-ac1f-4657-955a-a8613cc83209",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7985076962177716"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# exmple of interpreting \n",
    "ln_45=-np.log(0.45)\n",
    "ln_45"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c0e7944-2f11-4633-8bf3-746f80d76beb",
   "metadata": {},
   "source": [
    "the output tells us that loss is very big and our model is not very good"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd717762-2bb1-42c1-bb96-4b0f2ac00e09",
   "metadata": {},
   "source": [
    "#### practicing of calculating the loss function value over a dataset (weights are known)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9d923b82-82f5-4404-a02a-7833711b5887",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          X      prob  y\n",
      "0  0.496714  0.498357  0\n",
      "1 -0.138264  0.218142  0\n",
      "2  0.647689  0.573312  1\n",
      "3  1.523030  0.885549  1\n",
      "4 -0.234153  0.187200  1\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "np.random.seed(42)\n",
    "\n",
    "w = 2.0\n",
    "b = -1.0\n",
    "\n",
    "n_samples = 100\n",
    "X = np.random.randn(n_samples) \n",
    "\n",
    "z = w*X + b\n",
    "def sigmoid(z):\n",
    "    return 1/(1 + np.exp(-z))\n",
    "\n",
    "probs = sigmoid(z)\n",
    "y = np.random.binomial(1, probs)\n",
    "\n",
    "df = pd.DataFrame({'X': X, 'prob': probs, 'y': y})\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "198cd506-ed14-4d2d-890f-4a3ddbd61e24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the value of loss function with current weights: w = 2.0 and b = -1.0 is 0.43508814398787854\n"
     ]
    }
   ],
   "source": [
    "m = len(df)\n",
    "sum = 0\n",
    "for i in range(m): \n",
    "    sum+= df[\"y\"][i]*np.log(df[\"prob\"][i]) + (1-df[\"y\"][i])*np.log(1-df[\"prob\"][i])\n",
    "loss_val = -sum/m\n",
    "print(f\"the value of loss function with current weights: w = {w} and b = {b} is {loss_val}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04ddc202-8230-4695-a136-e71afafdbd31",
   "metadata": {},
   "source": [
    "**let's make a function from the code above:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b7be458e-e102-4c6a-968c-eb6a99369124",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_val(w, b, x, y):\n",
    "    z = w*x + b\n",
    "    probs = sigmoid(z)\n",
    "    m = len(probs)\n",
    "    sum = 0\n",
    "    for i in range(m):\n",
    "        sum += y[i]*np.log(probs[i]) + (1-y[i])*np.log(1-probs[i])\n",
    "    return -sum/m\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ff3543b5-d930-4ec7-803e-f9222f08ffef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.43508814398787854"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's test the function\n",
    "\n",
    "lv_21 = loss_val(w, b, df[\"X\"], df[\"y\"])\n",
    "lv_21"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "615ad815-46f1-4df5-a743-5ce96eee402a",
   "metadata": {},
   "source": [
    "the output above says that the function works "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5a9f948-e13e-45c6-9643-55badd5a17f0",
   "metadata": {},
   "source": [
    "#### now, let's test on various w and b manually:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "27e2cfa8-ee47-4337-a93d-282d1ec4b891",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5730380808445099"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w = 1.5\n",
    "b = 0.2\n",
    "lv = loss_val(w, b, df[\"X\"], df[\"y\"])\n",
    "lv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9d258e8-50f4-4267-9cf1-6b7e4a6264c8",
   "metadata": {},
   "source": [
    "bad weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "839ca695-a6d7-441e-9f1e-45232cf425e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9802465673291713"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w = 2.5\n",
    "b = 1.5\n",
    "lv = loss_val(w, b, df[\"X\"], df[\"y\"])\n",
    "lv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97386b1e-5262-4d41-bec7-c75385128e42",
   "metadata": {},
   "source": [
    "very bad weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1f9a75fe-afff-4df9-8e23-d93ab9b642f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.46343167904032156"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w = 1.8\n",
    "b = -1.8\n",
    "\n",
    "lv = loss_val(w, b, df[\"X\"], df[\"y\"])\n",
    "lv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "509b1ef9-1a2b-4a32-82ff-f62c47228654",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4928409f-e7cf-4b4d-b341-37ab3762a0d1",
   "metadata": {},
   "source": [
    "## How to find these $w$ and $b$? "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69bbcc6e-0b56-4919-a6e7-8823d268a352",
   "metadata": {},
   "source": [
    "Now, the whole \"train the model\" means finding "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bad69ba-d206-4cb6-8a8b-54c6e010672e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
